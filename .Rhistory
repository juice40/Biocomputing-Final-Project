instal.packages("swirl")
install.packages("swirl")
yes
install.packages("swirl")
swirl()
library("swirl")
swirl()
5
5
5 7
5 + 7
x<- 5 + 7
x
y
x-3
y<-x-3
y
c(1.1, 9, 3.14)
z<-c(1.1,9,3.14)
?
?c
?c
z
c(z+555+z)
c(z,555,z)
z*2+100
sqrt(z-1)
my_sqrt <- sqrt(z-1)
print
("print")
my_sqrt
my_div<- z/my_sqrt
my_div
c(1,2,3,4)+c(0,10)
c(1,2,3,4)+c(0,10,100)
z*2+1000
my_div
1
swirl()
library(swirl)
library(swirl)
()
swirl()
5+7
x<-5+7
x
y<-x-3
y
z<- x(1.1,9,3.14)
z<- c(1.1,9,3.14)
c
c()
?c
z
(z,555,z)
c(z,555,z)
z* 2 + 100
my_sqrt<-sqrt(z-1)
my_sqrt
my_div<-z/my_sqrt
my_div
c(1, 2, 3, 4)+c(0,10)
c(1, 2, 3, 4) + c(0, 10, 100)
c(1, 2, 3, 4) + c(0, 10, 1000)
z* 2 + 1000
my_div
swirl()
swirl()
1:20
pi:10
15:!
15:1
15:1
:
':'
?''
?""
?:
?':'
seq(1,20)
seq(0, 10, by=0.5)
seq(5, 10, length=30)
my_seq<-seq(5, 10, length=30)
length()
length(30)
length(my_seq)
1:length(my_seq)
seq(along.with = my_seq)
Type seq_along(my_seq)
seq_along(my_seq)
rep(0, times = 40)
rep(c(0, 1, 2), times = 10)
rep(c(0, 1, 2), each = 10)
num_vect<-c(.5,55,-`10`)
num_vect<-c(.5,55,-10)
num_vect<- c(0.5,55,-10)
num_vect<- c(0.5,55,-10,6)
tf<- num_vect is less than 1
tf<-'num_vect is less than 1'
tf <- num_vect < 1
tf
num_vect >= 6
c("my","name","is")
my_char <- c("My", "name", "is")
my
my_char
paste(my_char, collapse = " ")
c(my_char, "Justin"
)
c(my_char, "Justin")
my_name<-c(my_char, "Justin")
my_name
paste(my_name, collapse = " ")
paste("hello","world!",sep = "")
paste("Hello", "world!", sep = " ")
paste(c("X", "Y", "Z")), sep = ""
paste(c("X", "Y", "Z")), sep = "")
paste(1:3), sep = ""
paste(1:3+c("X", "Y", "Z")), sep = ""
paste(1:3+c("X", "Y", "Z")), sep =
paste(1:3+c("X", "Y", "Z")), sep = "")
paste(1:3,c("X", "Y", "Z")), sep = "")
paste(1:3,c("X", "Y", "Z")), sep = )
?
info()
skip()
paste(LETTERS, 1:4, sep = "-")
library(yarrr)
## CONTINUOUS DISTRIBUTIONS
## There are many different types of continuous probability distributions.
## UNIFORM DISTRIBUTION
## One of the simplest is the Uniform Distribution.
## We can use runif() to generate random numbers from a Uniform Distribution defined by a min and max.
runif(n = 10, min = 0.5, max = 1.5)
xs <- runif(n = 100, min = 50, max = 60)
hist(xs, freq = FALSE, xlim = c(45, 65), col = "lightblue")
x_values <- seq(45, 65, 0.1)
x_values <- seq(45, 65, 0.1)
pdf_values <- dunif(x = x_values, min = 50, max = 60)
lines(x_values, pdf_values, col = "hotpink", lwd = 2)
## http://www.ncdrisc.org/height-mean-ranking.html has data on mean heights in different countries
## mean height for women in Ireland is 165.1cm (born 1996) and for men is 178.9cm
## the distribution of height is defined by the mean, and the variance.
## https://ourworldindata.org/human-height gives the standard deviation for women's height as 7.07cm
## SD for men is 7.59cm
## With this information I can generate a random sample of male and female heights for any sample size
## using the continuous probability distribution Normal (or Gaussian) Distribution:
woman_mean <- 165.1
woman_sd <- 7.07
man_mean <- 178.9
man_sd <- 7.59
par(mfrow = c(2,2))
h10 <- rnorm(n = 10, mean = woman_mean, sd = woman_sd)
hist(h10, freq = FALSE, xlim = c(145, 190), ylim = c(0,0.1), main =  "n = 10",
xlab = "Height (cm)", col = "lightblue")
## The pdf or expected theoretical distribution can be plotted
x1 <- seq(145, 180,by = 0.5)
prob_norm <- dnorm(x = x1, mean = woman_mean, sd = woman_sd)
lines(seq(145, 180,by = 0.5), prob_norm, col = "hotpink")
legend("topright", "pdf", col = "hotpink", lty = 1, bty = "n")
h20 <- rnorm(n = 20, mean = woman_mean, sd = woman_sd)
hist(h20, freq = FALSE,xlim = c(145, 190), ylim = c(0,0.1), main =  "n = 20",
col = "lightblue", xlab = "Height (cm)", )
lines(seq(145, 180,by = 0.5), prob_norm, col = "hotpink")
h30 <- rnorm(n = 30, mean = woman_mean, sd = woman_sd)
hist(h30, freq = FALSE, xlim = c(145, 190), ylim = c(0,0.1), main =  "n = 30",
col = "lightblue", xlab = "Height (cm)")
lines(seq(145, 180,by = 0.5), prob_norm, col = "hotpink")
h100 <- rnorm(n = 100, mean = woman_mean, sd = woman_sd)
hist(h100, freq = FALSE, xlim = c(145, 190), ylim = c(0,0.1), main =  "n = 100",
col = "lightblue",  xlab = "Height (cm)")
lines(seq(145, 180,by = 0.5), prob_norm, col = "hotpink")
## Now I'll make a graph of the same data, heights for women, from the PDF
par(mfrow= c(1,1))
x <- seq(140, 190,by = 0.5)
y <- dnorm(seq(140, 190,by = 0.5), mean = woman_mean, sd = woman_sd)
plot(x, y, type = "l", col = "hotpink", bty = "l", ylim  = c(0,0.08))
## Lets look at Normal Distributions with different variances
## what if we used the male standard deviation instead of the female sd?
y2 <- dnorm(seq(140, 190,by = 0.5), mean = woman_mean, sd = man_sd)
lines(x, y2, type = "l", col = "green", bty = "l" )
y3 <- dnorm(seq(140, 190,by = 0.5), mean = woman_mean, sd = 15)
lines(x,y3, col = "darkblue" )
legend("topright", c(paste("sd = ", woman_sd), paste("sd = ", man_sd), "sd = 15"),
col = c("hotpink", "green", "darkblue"), lty = 1, bty = "n")
## Say I'd like to calculate the probability of a woman being between 165cm and 166cm
a <- 165
b <- 166
polygon(x = c(x[x >= a & x <= b],x[x == b], x[x == a]) ,
y = c(y[x >= a & x <= b], 0, 0),
col = "lightblue", lty = 3, lwd = 1)
## We can calculate the area of the shaded area using the difference between the cumulative distribution function
## for a and b. I'll switch to using a larger range as it's easier to see.
## So this time I'm calculating the probability of a woman's height lying between 165cm and 170cm
par(mfrow= c(3,1))
x <- seq(140, 190,by = 0.5)
plot(x, y, type = "l", col = "hotpink", bty = "l" )
a <- 165
b <- 170
polygon(x = c(x[x >= 0 & x <= a],x[x == a], 0) ,
y = c(y[x >= 0 & x <= a], 0, 0),
col = transparent("yellow", trans.val = 0.5), lty = 3, lwd = 1)
polygon(x = c(x[x >= 0 & x <= b],x[x == b], 0) ,
y = c(y[x >= 0 & x <= b], 0, 0),
col = transparent("lightblue", trans.val = 0.5), lty = 3, lwd = 1)
plot(x, y, type = "l", col = "hotpink", bty = "l" )
library(yarrr)
install.packages("yarrr")
library(yarrr)
library(BayesFactor)
ht<-read.csv("/Users/justin/Documents/Biostats/Practical 2/height.csv")
ht<-read.csv("/Users/justin/Documents/Biostats/Practical 2/heights.csv")
View(ht)
colnames(ht)<-c("student","parent","sex")
hist(ht$)
hist(ht$student,xlab="Height (cm)")
hist(ht$student,xlab="Height (cm)")
plot(density$student),xlab="Student height (cm)")
plot(density(ht$student),xlab="Student height (cm)")
hist(ht$student,xlab="Height (cm)",breaks=20)
plot(density(ht$student),xlab="Student height (cm)")
lines(density(ht$student[ht$sex=="female"],col="red"))
lines(density(ht$student[ht$sex=="female"]),col="red"))
lines(density(ht$student[ht$sex=="female"]),col="red")
lines(density(ht$student[ht$sex=="male"]),col="blue")
plot(density(ht$student),xlab="Student height (cm)",ylim=c(0,0.07)
plot(density(ht$student),xlab="Student height (cm)",ylim=c(0,0.07)
plot(density(ht$student),xlab="Student height (cm)",ylim=c(0,0.07))
lines(density(ht$student[ht$sex=="female"]),col="red")
lines(density(ht$student[ht$sex=="male"]),col="blue")
legend("topleft",c("All data","Females","Males"),col=c("black","red","blue",lty=1)
legend("topleft",c("All data","Females","Males"),col=c("black","red","blue",lty=1)
legend("topleft",c("All data","Females","Males"),col=c("black","red","blue",lty=1)
legend("topleft",c("All data","Females","Males"),col=c("black","red","blue"),lty=1)
legend("topleft",c("All data","Females","Males"),col=c("black","red","blue"),lty=1)
plot(ht$student,ht$parent,xlab="Student height(cm"),ylab="Paten height (cm)")
plot(ht$student,ht$parent,xlab="Student height(cm)",ylab="Parent height (cm)")
ht$colour<-"blue"
ht$colour[ht$sex=="female"]<-"red"
plot(ht$student,ht$parent,xlab="Student height (cm)",ylab="Parent height (cm),pch=16,col=ht$colour")
plot(ht$student,ht$parent,xlab="Student height (cm)",ylab="Parent height (cm),pch=16,col=ht$colour")
plot(ht$student,ht$parent,xlab="Student height (cm)",ylab="Parent height (cm)")
ht$colour<-"blue"
ht$colour[ht$sex=="female"]<-"red"
plot(ht$student,ht$parent,xlab="Student height (cm)",ylab="Parent height (cm)",pch=16,col=ht$colour)
##our null hypothesis is that  males and females are the same height or, in formal language
## that the distribution of male and female heights are statisitically
##indistinguishable
t.test(ht$student[ht$sex=="fmeale"],ht$student[ht$sex=="male"])
##our null hypothesis is that  males and females are the same height or, in formal language
## that the distribution of male and female heights are statisitically
##indistinguishable
t.test(ht$student[ht$sex=="female"],ht$student[ht$sex=="male"])
##want a p-value >0.05
##p-value of 1.032e-14, therefore, our null is incorrect since p-val is <.05
##hence, male and female heights are statistically significantly different
t.test(ht$sex=="female",mu=165)
t.test(ht$student[ht$sex=="male"],mu=179)
t.test(ht$student,ht$parent,paired=TRUE)
ht$parent<-as.numeric(ht$parent)
#Paired T-test
t.test(ht$student,ht$parent,paired=TRUE)
t.test(ht$student-ht$parent,mu=0)
##One-tailed vs. two-tailed tests
##two test is comparing one group and another
t.test(ht$student,ht$parent,paired=TRUE,alternative="greater")
##Part 3: distributions, assumptions, and stat tests
#without alteration, t-test assumes a normal distribution
##use Shapiro-Wilk test to formally test for normality
shapiro.test(ht$student[ht$sex=="male"])
shapiro.test(ht$student[ht$sex=="female"])
shapiro.test(ht$student)
shapiro.test(ht$student)
##normal distribution for the whole set
wilcox.test(ht$student,ht$parent)
wilcox.test(ht$student,ht$parent,paired=TRUE)
##paired=TRUE is for same group under diff conditions
##paired=FALSE is for comparing two diff groups
6test<-seq(1,100)
##paired=TRUE is for same group under diff conditions
##paired=FALSE is for comparing two diff groups
sixtest<-seq(1,100)
shapiro.test(sixtest)
##Part 4:model
plot(ht$student,ht$parent,xlab="Student height (cm)",ylab="Parent height (cm)",pch=16,col=ht$colour)
mymodel<-lm(ht$parent~ht$student)
## the "~" asks R to fit linear model of parent height as a function of
# student height
## ht$parent: y var and ht$student: x var
abline(mymodel)
summary(mymodel)
##following the y=mx+b format, where this info is elicited from summary of myline
## low p-vaulue; therefore, there is a statistical difference btw values
mymodel<-lm(ht$parent~ht$student+0)
##following the y=mx+b format, where this info is elicited from summary of myline
## low p-vaulue; therefore, there is a statistical difference btw values
mymodel<-lm(ht$parent~ht$student+0)
source("~/Documents/Biostats/Practical 2/R Practical 2 .R")
abline(mymodel,col="green")
summary(mymodel)
##Question 8
intvsage<-data.frame(iq=c(92,104,112,79,131,100,99,101,90,114),age=c(42,19,33,35,30,41,79,67,29,18))
view(intvsage)
View(intvsage)
fire<-lm(invstage$iq~intvsage$age)
fire<-lm(intvsage$iq~intvsage$age)
summary(fire)
fire<-lm(intvsage$iq~2*intvsage$age)
summary(fire)
fire<-lm(intvsage$iq~*intvsage$age)
debugSource("~/Documents/Biostats/Practical 2/R Practical 2 .R")
source("~/Documents/Biostats/Practice/R script for lecture 5 continuous probability.R")
install_github("jacintak/biostats",build_vignettes=TRUE, dependecies=TRUE, force=TRUE)
library(readr)quakes <- read_csv("Documents/Biostats/Practice/quakes.csv")
library(readr) quakes <- read_csv("Documents/Biostats/Practice/quakes.csv")
library(readr)
quakes <- read_csv("Documents/Biostats/Practice/quakes.csv")
View(quakes)
remotes::install_github("jacintak/biostats",build_vignettes=TRUE, dependecies=TRUE, force=TRUE)
a<-2+2
a
# Box and whiskers plot of epicenter depth (y-axis) against intensity (x-axis)
boxplot(intensity ~ depth, data = quakes, ylab = "Depth (km)", xlab = "Intensity category", col = "tomato2")
# Import data
quakes <- read.csv("quakes.csv")
# Import data
quakes <- read.csv("quakes.csv")
# Import data
quakes <- read.csv("quakes.csv")
# Import data
quakes <- read.csv("quakes.csv")
source("~/Documents/Biostats/Practice/Comp Pratice Sesh 4.R")
source("~/Documents/Biostats/Practice/Comp Pratice Sesh 4.R")
source("~/Documents/Biostats/Practice/Comp Pratice Sesh 4.R")
source("~/Documents/Biostats/Practice/Comp Pratice Sesh 4.R")
# Import data
quakes <- read.csv("quakes.csv")
# Import data
quakes <- read.csv("~/Documents/Biostats/Practice/quakes.csv")
# Check data structure
str(quakes)
# Exploratory analysis
hist(quakes$mag) # plot histogram of earthquake magnitude
plot(depth ~ mag, quakes) # plot of epicenter depth (y-axis) against Richter Magnitude (x-axis)
# Create two categories of magnitude intensity (light or strong) for statistical analysis
quakes$intensity <- "light"
quakes[quakes$mag >= 5,]$intensity <- "strong" # For Richter Magnitude 5 and above
View(quakes)
# Generate frequency table of intensity categories
table(quakes$Intensity)
# Two sample t-test
# H0: There is no difference in epicenter depth between earthquake intensities
t.test(depth ~ intensity, data = quakes, alternative = "two.sided", paired = FALSE
# Box and whiskers plot of epicenter depth (y-axis) against intensity (x-axis)
boxplot(intensity ~ depth, data = quakes, ylab = "Depth (km)", xlab = "Intensity category", col = "tomato2")
# Box and whiskers plot of epicenter depth (y-axis) against intensity (x-axis)
boxplot(intensity ~ depth, data = quakes, ylab = "Depth (km)", xlab = "Intensity category", col = "tomato2")
# Two sample t-test
# H0: There is no difference in epicenter depth between earthquake intensities
t.test(depth ~ intensity, data = quakes, alternative = "two.sided", paired = FALSE
# Two sample t-test
# H0: There is no difference in epicenter depth between earthquake intensities
t.test(depth ~ intensity, data = quakes, alternative = "two.sided", paired = FALSE)
# Two sample t-test
# H0: There is no difference in epicenter depth between earthquake intensities
t.test(depth ~ intensity, data = quakes, alternative = "two.sided", paired = FALSE)
boxplot(intensity ~ depth, data = quakes, ylab = "Depth (km)", xlab = "Intensity category", col = "tomato2")
if (x < 100) {
cat("Sorry but you failed")
} else {
if (x = 100) {
# check if the sum is more or less than 100
if (tableSum > 100) {
print("Sorry but you failed")
}else{
print("Good job")
}
checkAssignment("smith.csv")
# Set working directory
setwd(/Users/justin/Desktop/tutorial/Biocomputing-Final-Project/)
# Set working directory
setwd(Users/justin/Desktop/tutorial/Biocomputing-Final-Project/)
# Set working directory
setwd(Users/justin/Desktop/tutorial/Biocomputing-Final-Project)
# Set working directory
setwd(/Users/justin/Desktop/tutorial/Biocomputing-Final-Project)
# Set working directory
setwd("/Users/justin/Desktop/tutorial/Biocomputing-Final-Project")
#The function will convert all .txt files in a directory to .csv files
TxtToCsv=function(directory){
# Make a object with all of the files that are .txt and not currently
# comma delimited
countrycsv<-list.files(directory, pattern = ".txt")
#Set working directory to where you would like to place the new .csv files
setwd(directory)
#For loop to change each .txt file to a .csv file
for (i in 1:length(countrycsv)){
FILE<-read.table(file=countrycsv[i],header=TRUE,sep="")
write.table(FILE,file=paste0(directory,sub(".txt","",countrycsv[i]),".csv"),
row.names=F,quote=F,sep=",")
}
}
# Function  that combines the data from CountryX and CountryY into a large
# .csv file and allows the user to decide the purpose of the NA rows
Combined_CSV=function(directory1, directory2, directory3){
setwd(directory1)
All_DataX=data.frame(gender=character(), age=numeric(), marker01=numeric(),
marker02=numeric(), marker03=numeric(), marker04=numeric(), marker05=numeric(),
marker06=numeric(), marker07=numeric(), marker08=numeric(), marker09=numeric(),
marker10=numeric(), country=character(), dayofyear=numeric())
#Adding X Files to the DF
listfilesX=list.files(pattern=".csv")
#For Loop to read through each X file
for (i in 1:length(listfilesX)){
X=read.csv(listfilesX[i])
#Add the country to each X row
X$country="X"
#Add the day of year to each row
X$dayofyear=as.numeric(substr(listfiles[i], 8, 10))
All_DataX = rbind(All_DataX, X)
}
#Creating the Large .csv with all Y data from all screens
setwd(directory2)
#Creating a DF for all of the data
All_DataY=data.frame(gender=character(), age=numeric(), marker01=numeric(), marker02=numeric(), marker03=numeric(), marker04=numeric(), marker05=numeric(), marker06=numeric(), marker07=numeric(), marker08=numeric(), marker09=numeric(), marker10=numeric(), country=character(), dayofyear=numeric())
#Adding X Files to the DF
listfilesY=list.files(pattern=".csv")
#For loop to read through each Y file
for (i in 1:length(listfilesY)){
Y=read.csv(listfilesY[i])
#Add the country to each Y row
Y$country="Y"
#Add the day of year to each row
Y$dayofyear=as.numeric(substr(listfilesY[i], 8, 10))
All_DataY = rbind(All_DataY, Y)
}
All_Data_Both=rbind(All_DataX, All_DataY)
setwd(directory3)
#Allow the user to decide what to do with NA rows
print("What would you like to do with variables with NA in dataset?")
print("Type 1 to remove NA rows")
print("Type 2 to keep NA rows but display a warning")
print("Type 3 to keep the rows with NA without warning")
Number_Chosen=readline(prompt= "Type Number: ")
#For loop to bind data if user chooses to do nothing with the NA
if (Number_Chosen==3){
All_Data_Both= rbind(All_DataX, All_DataY)
write.csv(All_Data_Both, file= "All_Data_Both.csv")
}
#For loop to print a warning if the user chooses to
if (Number_Chosen==2){
All_Data_Both= rbind(All_DataX, All_DataY)
write.csv(All_Data_Both, file= "All_Data_Both.csv")
print("Warning: Rows with no data are present")
}
#For loop to remove the NA rows if the user chooses to
if (Number_Chosen==1){
All_Data_Both= rbind(All_DataX, All_DataY)
All_Data_Both=na.omit(All_Data_Both)
write.csv(All_Data_Both, file= "All_Data_Both.csv")
}
}
